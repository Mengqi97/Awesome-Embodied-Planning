# Awesome Embodied Planning

A curated collection of embodied planning methods, benchmarks, and detailed paper notesâ€”built to support and grow the embodied planning community.
é¢å‘å…·èº«è§„åˆ’ç¤¾åŒºï¼šæ•´ç†æ–¹æ³•ã€åŸºå‡†ä¸è¯¦ç»†è®ºæ–‡ç¬”è®°ï¼Œæ¨åŠ¨ç¤¾åŒºå‘å±•ã€‚

**Legend**

- `ğŸŒ¿` = `CCF-A` or `ICLR`
- `ğŸƒ` = `CCF-B`
- `ğŸŒ±` = `CCF-C`
- `â­` = others / unclassified


## Contents

- [Benchmarks](#benchmarks)
- [Methods](#methods)
- [PaperNotes](#PaperNotes)

## Benchmarks

- [2025.08|â­ Arxiv] AgentWorld: an interactive simulation platform for scene construction and mobile robotic manipulation [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/yizhengzhang1/agent_world) [![project](https://img.shields.io/badge/project--blue?style=social&logo=googlechrome)](https://yizhengzhang1.github.io/agent_world/)
- [2025.06|ğŸŒ¿ CCF-A ACL] AmbiK: dataset of ambiguous tasks in kitchen environment  [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/cog-model/AmbiK-dataset)
- [2025.07|â­ Arxiv] CookBench: a long-horizon embodied planning benchmark for complex cooking scenarios ![github](https://img.shields.io/badge/upcoming--blue?style=social&logo=github)
- [2025.02|â­ Arxiv] EmbodiedBench: comprehensive benchmarking multi-modal large language models for vision-driven embodied agents [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/EmbodiedBench/EmbodiedBench)[![project](https://img.shields.io/badge/project--blue?style=social&logo=googlechrome)](https://embodiedbench.github.io/)
- [2025.07|â­ Arxiv] EmbRACE-3K: embodied reasoning and action in complex environments 
- [2025.02|â­ Arxiv] ET-plan-bench: embodied task-level planning benchmark towards spatial-temporal cognition with foundation models 
- [2025.08|â­ Arxiv] Large VLM-based vision-language-action models for robotic manipulation: a survey [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)
- [2024.10|ğŸŒ¿ ICLR] PARTNR: a benchmark for planning and reasoning in embodied multi-agent tasks [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/facebookresearch/partnr-planner)
- [2024.07|ğŸƒ CCF-B ECCV] ReALFRED: An Embodied Instruction Following Benchmark in Photo-Realistic Environments [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/snumprlab/realfred)
- [2021.03|ğŸŒ¿ ICLR] ALFWorld: Aligning Text and Embodied Environments for Interactive Learning [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/alfworld/alfworld)[![project](https://img.shields.io/badge/project--blue?style=social&logo=googlechrome)](https://alfworld.github.io/)
- [2020.06|ğŸŒ¿ CCF-A CVPR] ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/askforalfred/alfred)
- [2018.06|ğŸŒ¿ CCF-A CVPR] VirtualHome: Simulating Household Activities Via Programs [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/xavierpuigf/virtualhome)
- [2021.03|ğŸŒ¿ CCF-A AAAI] TEACh: Task-driven Embodied Agents that Chat [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/alexa/teach)[![project](https://img.shields.io/badge/project--blue?style=social&logo=googlechrome)](https://teachingalfred.github.io/)
- [2018.09|ğŸŒ¿ CCF-A CVPR] IQA: visual question answering in interactive environments [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/danielgordon10/thor-iqa-cvpr-2018)

## Methods

- [2025.02|ğŸŒ¿ CCF-A CVPR] Magma: A Foundation Model for Multimodal AI Agents [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/microsoft/Magma)[![project](https://img.shields.io/badge/project--blue?style=social&logo=googlechrome)](https://microsoft.github.io/Magma/)
- [2024.10|ğŸƒ CCF-B ECCV] Octopus: embodied vision-language programmer from environmental feedback [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/dongyh20/Octopus)[![project](https://img.shields.io/badge/project--blue?style=social&logo=googlechrome)](https://choiszt.github.io/Octopus/)
- [2025.01|â­ Arxiv] P3Nav: a unified framework for embodied navigation integrating perception, planning, and prediction 
- [2025.07|â­ Arxiv] World-aware planning narratives enhance large vision-language model planner 
- [2024.12|â­ Arxiv] DaDu-E: Rethinking the Role of Large Language Model in Robotic Computing Pipeline[![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/RLC-Lab/DaDu_E)[![project](https://img.shields.io/badge/project--blue?style=social&logo=googlechrome)](https://rlc-lab.github.io/dadu-e/)
- [2023.07|â­ Arxiv] Embodied task planning with large language models [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/Gary3410/TaPA)[![project](https://img.shields.io/badge/project--blue?style=social&logo=googlechrome)](https://gary3410.github.io/TaPA/)
- [2017.07|ğŸƒ CCF-B EMNLP] Mapping instructions and visual observations to actions with reinforcement learning [![github](https://img.shields.io/badge/github--blue?style=social&logo=github)](https://github.com/lil-lab/blocks)[![project](https://img.shields.io/badge/project--blue?style=social&logo=googlechrome)](https://katefvision.github.io/LanguageGrounding/Slides/57.pdf)
- [2017.08|ğŸŒ¿ CCF-A ICCV] Visual semantic planning using deep successor representations 

## PaperNotes
- [2023.05|ğŸƒ CCF-B ICRA] [Code as Policies-Language Model Programs for Embodied Control](https://github.com/Mengqi97/Awesome-Embodied-Planning/blob/main/papernote/2023-icra-cap.md)

## Contributing

Feelfree to add papers by pulling requests.
